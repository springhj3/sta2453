{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The dataframe is created by merging all CSV files\n",
    "df = pd.read_csv(r'C:\\Users\\sprin\\Downloads\\SIMC_OverlapTiffsWithPP\\SIMC_OverlapTiffsWithPP\\SIMC.Overlap.csv\\merged_data.csv')\n",
    "\n",
    "feature_cols = [\n",
    "    \"Area..ABD.\", \"Area..Filled.\", \"Width\", \"Length\", \"Volume..ABD.\", \"Volume..ESD.\", \n",
    "    \"Diameter..ABD.\", \"Diameter..ESD.\", \"Feret.Angle.Max\", \"Feret.Angle.Min\", \"Transparency\", \n",
    "    \"Sum.Intensity\", \"Intensity\", \"Sigma.Intensity\", \"Edge.Gradient\"\n",
    "]\n",
    "target_col = \"Class\"\n",
    "\n",
    "selected_classes = [\"Calanoid_1\", \"Cyclopoid_1\", \"Bosmina_1\", \"Herpacticoida\", \"Chironomid\", \"Chydoridae\", \"Daphnia\"]\n",
    "\n",
    "# Assign \"Others\" to all plankton not in selected_classes\n",
    "df[target_col] = df[target_col].apply(lambda x: x if x in selected_classes else \"Others\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will do logistic regression. \n",
    "We need some assumptions for logistic regression. First is that features needed to be linearly separable. Since features of zooplankton data are not separable but we will use logistic regression as a baseline. As logistic regression is simple and interpretable, as well as handle imbalanced classes well, I choose logistic regression with a baseline. \n",
    "Second is that there should be no multicolinearity. To remove multicolinearity, we will use PCA as EDA. \n",
    "Third is that features are on the same scale however we found that range is extremely large. Therefore we will standardize the features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no missing values in the features.\n",
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    Bosmina_1       0.02      0.85      0.03       575\n",
      "   Calanoid_1       0.51      0.23      0.32     43043\n",
      "   Chironomid       0.00      0.25      0.00         8\n",
      "   Chydoridae       0.00      0.00      0.00         9\n",
      "  Cyclopoid_1       0.50      0.12      0.19     39596\n",
      "      Daphnia       0.00      0.39      0.00       112\n",
      "Herpacticoida       0.00      0.34      0.01       121\n",
      "       Others       0.89      0.74      0.80    164452\n",
      "\n",
      "     accuracy                           0.55    247916\n",
      "    macro avg       0.24      0.36      0.17    247916\n",
      " weighted avg       0.76      0.55      0.62    247916\n",
      "\n",
      "Confusion Matrix:\n",
      " [[   487      3      0      5     22      7     46      5]\n",
      " [  1740  10007   9739    794   3782   7136   3679   6166]\n",
      " [     0      4      2      0      0      0      0      2]\n",
      " [     2      2      0      0      2      0      3      0]\n",
      " [  3036   2878   1124   1534   4704   8500   8401   9419]\n",
      " [     7     28     10      2      7     44      9      5]\n",
      " [     8      8      1      3      4     19     41     37]\n",
      " [ 25294   6716   4868    229    843   1993   3278 121231]]\n"
     ]
    }
   ],
   "source": [
    "X = df[feature_cols]\n",
    "y = df[target_col]\n",
    "\n",
    "if X.isnull().values.any():\n",
    "    print(\"There are missing values in the features.\")\n",
    "else:\n",
    "    print(\"There are no missing values in the features.\")\n",
    "\n",
    "# Standardize features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_pca, y, test_size=0.2, random_state=2453, stratify=y\n",
    ")\n",
    "\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression(class_weight=\"balanced\", max_iter=1000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification Report:\n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "    Bosmina_1       0.00      0.93      0.01       575\n",
      "   Calanoid_1       0.54      0.16      0.24     43043\n",
      "   Chironomid       0.00      0.25      0.00         8\n",
      "   Chydoridae       0.00      0.56      0.00         9\n",
      "  Cyclopoid_1       0.49      0.12      0.20     39596\n",
      "      Daphnia       0.00      0.45      0.01       112\n",
      "Herpacticoida       0.00      0.45      0.00       121\n",
      "       Others       0.76      0.18      0.29    164452\n",
      "\n",
      "     accuracy                           0.17    247916\n",
      "    macro avg       0.23      0.39      0.09    247916\n",
      " weighted avg       0.67      0.17      0.27    247916\n",
      "\n",
      "Confusion Matrix:\n",
      " [[   537      0      0     28      0      8      2      0]\n",
      " [  1853   6674   3923   7204   3934   8036   3136   8283]\n",
      " [     0      0      2      0      0      0      1      5]\n",
      " [     1      1      0      5      1      0      1      0]\n",
      " [  2892   4785    962   8968   4861   3910  12073   1145]\n",
      " [     3      4      7     11     15     50     18      4]\n",
      " [     1      3      2      9      4     15     54     33]\n",
      " [112514    928   1485   4549   1014   2465  12048  29449]]\n"
     ]
    }
   ],
   "source": [
    "# Standardize features\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_pca, y, test_size=0.2, random_state=2453, stratify=y\n",
    ")\n",
    "\n",
    "# Logistic Regression\n",
    "log_reg = LogisticRegression(class_weight=\"balanced\", max_iter=1000)\n",
    "log_reg.fit(X_train, y_train)\n",
    "\n",
    "y_pred = log_reg.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
